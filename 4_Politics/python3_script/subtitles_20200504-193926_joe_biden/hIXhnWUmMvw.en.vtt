WEBVTT
Kind: captions
Language: en

00:00:06.680 --> 00:00:08.980
 Harvard professor Shoshana Zuboff 

00:00:09.040 --> 00:00:11.460
 is often called the Karl Marx of our time. 

00:00:12.040 --> 00:00:15.215
 Her monumental book The Age of Surveillance Capitalism 

00:00:15.220 --> 00:00:18.980
 exhibited the dubious mechanisms of our digital economy. 

00:00:19.500 --> 00:00:22.500
 According to Zuboff, our personal and private experiences, 

00:00:22.505 --> 00:00:25.425
 been hijacked by Silicon Valley 

00:00:25.425 --> 00:00:28.165
 and used as the raw materials 

00:00:28.165 --> 00:00:30.925
 into extremely valuable digital products. 

00:00:30.925 --> 00:00:34.960
 The term "surveillance capitalism" is not an arbitrary term. 

00:00:35.260 --> 00:00:37.720
 Why "monitoring"? 

00:00:37.720 --> 00:00:42.420
 Because these are necessarily operations made in a way that 

00:00:42.420 --> 00:00:48.820
 so they are undetectable, incomprehensible and hidden in rhetoric, 

00:00:48.880 --> 00:00:51.900
 for the purpose of diverting our attention 

00:00:52.040 --> 00:00:54.960
 creating obscurity 

00:00:54.960 --> 00:00:59.820
 and simply cheat us all 

00:01:00.720 --> 00:01:02.200
 "Connecting them ..." "Don't be evil" 

00:01:02.805 --> 00:01:04.415
 "Connecting them ..." "Humanity ..." 

00:01:04.725 --> 00:01:05.725
 "Don't be evil" 

00:01:05.865 --> 00:01:09.295
 "Humanity ..." "Humanity ..." "It's about giving power to the individual." 

00:01:09.825 --> 00:01:11.595
 "The future is private." 

00:01:12.585 --> 00:01:15.505
 What is really happening with your Facebook photos? 

00:01:15.545 --> 00:01:18.485
 Why are there hidden microphones in Google Nest? 

00:01:18.745 --> 00:01:22.095
 And Pokemon Go is exhibited as child lockers? 

00:01:22.625 --> 00:01:25.515
 In this section of Backlight, Shoshana Zuboff reveals, 

00:01:25.520 --> 00:01:28.120
 how Silicon Valley leads us behind the light. 

00:01:28.120 --> 00:01:29.780
 In the most skillful way. 

00:01:31.400 --> 00:01:36.100
 The big data robbery 

00:01:37.120 --> 00:01:40.080
 How is all this put into play, 

00:01:40.080 --> 00:01:44.660
 when I buy a pair of shoes on the internet? 

00:01:45.560 --> 00:01:50.640
 Some people say to me: 

00:01:50.640 --> 00:01:54.475
 "But Professor Zuboff, I love targeted advertising!" 

00:01:54.480 --> 00:01:57.200
 "They are so helpful!" 

00:01:57.200 --> 00:01:59.680
 or "I enjoy personalized services!". 

00:01:59.680 --> 00:02:01.980
 Sometimes people say: 

00:02:02.640 --> 00:02:08.220
 "I have nothing to hide, so I don't care what they collect!" 

00:02:08.700 --> 00:02:14.000
 Each of these statements is a deep misunderstanding, 

00:02:14.000 --> 00:02:15.620
 of what is actually going on. 

00:02:15.980 --> 00:02:21.680
 We believe that the only personal information they hold about us, 

00:02:21.680 --> 00:02:23.100
 is what we have given to them. 

00:02:24.480 --> 00:02:28.380
 And we think we have control over what we give them. 

00:02:28.600 --> 00:02:34.280
 And that's why we think our calculations or trade-offs are something 

00:02:34.285 --> 00:02:37.505
 that we somehow manage - that we understand. 

00:02:37.660 --> 00:02:39.640
 What really happens is, 

00:02:39.660 --> 00:02:41.940
 that we provide them with personal information, 

00:02:41.940 --> 00:02:44.380
 but the information we provide ourselves, 

00:02:44.380 --> 00:02:47.080
 is the least important part 

00:02:47.080 --> 00:02:49.740
 of the information collected about us. 

00:02:53.320 --> 00:02:55.880
 Thanks to their navigation and search engine, 

00:02:55.880 --> 00:02:58.520
 Google at all times where we are 

00:02:58.520 --> 00:03:00.360
 and what we think. 

00:03:00.560 --> 00:03:04.000
 Facebook knows our hobbies, preferences and friends, 

00:03:04.000 --> 00:03:08.000
 because they collect a lot of information from the digital tracks, 

00:03:08.000 --> 00:03:09.820
 we inadvertently leave us alone. 

00:03:10.140 --> 00:03:12.540
 Spelling errors in your keywords. 

00:03:12.780 --> 00:03:14.320
 Which color buttons you prefer. 

00:03:14.560 --> 00:03:17.440
 How fast you type. How fast you drive a car. 

00:03:17.780 --> 00:03:19.620
 Residual data. 

00:03:23.240 --> 00:03:24.940
 Back when it started, 

00:03:25.660 --> 00:03:29.700
 back in 2000, 2001, 2002, 

00:03:29.700 --> 00:03:34.340
 at that time this information was considered "extra data". 

00:03:34.340 --> 00:03:36.920
 They were considered waste products. 

00:03:37.020 --> 00:03:42.520
 And this information was called "digital exhaust" or "data exhaust". 

00:03:42.520 --> 00:03:47.460
 Over time, there was an understanding that these so-called waste products 

00:03:47.460 --> 00:03:50.580
 contained a wealth of predictive information. 

00:03:56.480 --> 00:03:59.360
 The purpose of retaining information about searches is quality considerations. 

00:03:59.365 --> 00:04:02.305
 For example, Google's spelling correction, 

00:04:02.305 --> 00:04:05.485
 our "Did you mean ..." feature, which shows up on Google, 

00:04:05.560 --> 00:04:09.900
 is built using long periods of data on, 

00:04:09.900 --> 00:04:12.260
 when someone searches for something, 

00:04:12.260 --> 00:04:15.680
 and immediately make a corrected search, 

00:04:15.680 --> 00:04:17.780
 and we learn from those corrections 

00:04:17.780 --> 00:04:20.360
 And it takes more than 30 days of data, 

00:04:20.400 --> 00:04:23.260
 to build a world-class spell correction, like the one we have. 

00:04:25.900 --> 00:04:27.580
 The companies usually say, 

00:04:27.580 --> 00:04:31.020
 we collect data so we can improve our services. 

00:04:31.020 --> 00:04:33.520
 And that is true. They collect data. 

00:04:33.520 --> 00:04:38.380
 And some of it is used to improve services. 

00:04:38.860 --> 00:04:42.760
 But an even bigger part is analyzed, 

00:04:42.760 --> 00:04:46.500
 to train what they call models - 

00:04:46.840 --> 00:04:49.280
 patterns of human behavior. 

00:04:49.780 --> 00:04:53.920
 So once I have extensive training models, 

00:04:53.920 --> 00:05:00.980
 I can see how people with these characteristics typically behave over time. 

00:05:00.980 --> 00:05:05.200
 And it allows me to put your data into that "arc" 

00:05:05.200 --> 00:05:08.100
 and predict how you are likely to act, 

00:05:08.100 --> 00:05:10.960
 not only now, but at a later date. 

00:05:10.960 --> 00:05:14.420
 This is what I call behavioral excess. 

00:05:14.420 --> 00:05:18.800
 These streams of data are rich in predictive data. 

00:05:18.800 --> 00:05:20.340
 Why "surplus"? 

00:05:20.340 --> 00:05:24.420
 Because from the beginning, they (the data streams) contained more data, 

00:05:24.420 --> 00:05:27.860
 than was necessary to improve products and services. 

00:05:29.740 --> 00:05:32.160
 Just as soon as you have a behavior surplus 

00:05:32.160 --> 00:05:36.000
 - comprehensive information on hundreds of millions of people's behavior - 

00:05:36.180 --> 00:05:39.620
 you can start predicting specific group preferences. 

00:05:40.320 --> 00:05:43.300
 Think of popular shoes for male leaders. 

00:05:43.300 --> 00:05:47.360
 Or the preferred restaurants for a group of people with the same zip code. 

00:05:48.360 --> 00:05:51.860
 Maybe they predict where I eat tonight? 

00:05:51.860 --> 00:05:54.780
 How can I imagine what they predict about me? 

00:05:55.660 --> 00:05:57.960
 At the simplest level, 

00:05:57.960 --> 00:06:05.360
 they can predict the type of food you want right now. 

00:06:05.720 --> 00:06:08.020
 And then 

00:06:08.260 --> 00:06:16.120
 sell that prediction - auction it off - to their business customers in the hospitality industry, 

00:06:16.200 --> 00:06:20.140
 which then sends you a quick ad: 

00:06:20.260 --> 00:06:24.380
 "We know you're in the mood for a delicious pasta dish tonight." 

00:06:24.380 --> 00:06:27.920
 "We can invite you to a restaurant and here is a discount coupon." 

00:06:28.860 --> 00:06:36.720
 Some say it is unlikely to achieve anything with targeted advertising 

00:06:36.720 --> 00:06:44.500
 because people have their own free will, and don't buy a pair of shoes just because they have an advertisement in front of them. 

00:06:47.540 --> 00:06:54.400
 I think one of the misconceptions 

00:06:54.400 --> 00:06:57.000
 which is important for us to move away from, 

00:06:57.000 --> 00:07:07.160
 is that surveillance capitalism only manifests itself in our lives when we are online. 

00:07:07.380 --> 00:07:09.895
 Or that it is somehow just limiting itself 

00:07:09.900 --> 00:07:12.460
 online targeted marketing. 

00:07:12.460 --> 00:07:14.500
 It's easy for us to say, 

00:07:14.500 --> 00:07:16.680
 that things don't affect me. 

00:07:16.680 --> 00:07:18.100
 The fact is, 

00:07:18.100 --> 00:07:24.400
 it is implemented in a layer that is not available to us. 

00:07:26.780 --> 00:07:30.640
 We have no idea what algorithms today can predict about us. 

00:07:30.640 --> 00:07:33.580
 Or about what behavior information is used for it. 

00:07:34.540 --> 00:07:37.760
 Something as simple as buying a particular kind of shampoo, 

00:07:38.065 --> 00:07:40.945
 may disclose essential information about us. 

00:07:41.380 --> 00:07:44.400
 For example, the New York Times described a case, 

00:07:44.400 --> 00:07:49.180
 where a supermarket chain knew a girl had become pregnant before she even did 

00:07:49.320 --> 00:07:51.440
 - or was ready to share the news. 

00:07:52.160 --> 00:07:59.980
 The market algorithms discovered that the girl switched from perfumed shampoo to more neutral scented products. 

00:08:00.160 --> 00:08:03.540
 Because the sense of smell sharpens when you become pregnant, 

00:08:03.580 --> 00:08:07.120
 the market algorithm assumed that the girl had to be pregnant. 

00:08:07.660 --> 00:08:08.820
 Her father did not know. 

00:08:09.195 --> 00:08:12.415
 Until he was sent repeated offers 

00:08:12.420 --> 00:08:14.320
 on newborn products. 

00:08:15.060 --> 00:08:18.900
 Thanks to the analysis of trillions of terabytes of behavioral data, 

00:08:19.160 --> 00:08:22.160
 which we inadvertently leave around the digital world, 

00:08:22.160 --> 00:08:25.940
 Big Tech sometimes knows us better than we know ourselves. 

00:08:25.945 --> 00:08:29.195
 They can predict things like our personality, 

00:08:29.240 --> 00:08:31.580
 our feelings, 

00:08:31.580 --> 00:08:33.640
 our sexual preferences, 

00:08:33.640 --> 00:08:35.520
 our political stand. 

00:08:35.740 --> 00:08:41.260
 A whole host of things we never intended to disclose. 

00:08:42.780 --> 00:08:47.640
 The predictive value that Big Tech can extract from residual data is huge. 

00:08:47.780 --> 00:08:50.755
 The family portraits that we post on our Facebook pages, 

00:08:50.760 --> 00:08:52.500
 contains residual data, 

00:08:52.500 --> 00:08:55.920
 from which large amounts of valuable knowledge can be extracted. 

00:08:56.600 --> 00:09:04.300
 Let's say I put the photo album with pictures of my kids' birthday parties online - on the Facebook pages. 

00:09:04.300 --> 00:09:10.920
 What we have trouble understanding is that the most important thing is not the pictures as such. 

00:09:11.320 --> 00:09:14.240
 These are the predictive signals, 

00:09:14.780 --> 00:09:18.820
 which these companies can steal from the pictures. 

00:09:19.160 --> 00:09:21.640
 It's not just my face, 

00:09:21.640 --> 00:09:30.000
 but it allows them to analyze the hundreds of muscles in my face. 

00:09:32.320 --> 00:09:35.075
 To upload innocent snapshots on your Facebook page, 

00:09:35.075 --> 00:09:37.915
 can have unforeseen consequences. 

00:09:37.920 --> 00:09:40.900
 For example, our faces are used to train algorithms 

00:09:40.900 --> 00:09:43.540
 in recognizing facial features. 

00:09:43.700 --> 00:09:46.220
 And we have no idea whatsoever, 

00:09:46.220 --> 00:09:49.375
 about what the face recognition software is used for. 

00:09:49.375 --> 00:09:52.535
 These data streams with powerful predictive signals, 

00:09:52.535 --> 00:09:54.955
 are born into the new factories 

00:09:54.955 --> 00:09:57.695
 - the calculation factories - 

00:09:57.700 --> 00:10:01.780
 analyzed for human behavior predictions, 

00:10:02.140 --> 00:10:04.880
 and these predictions are then sold. 

00:10:05.315 --> 00:10:08.285
 Who are they being sold to? They will not be sold to us. 

00:10:08.285 --> 00:10:10.540
 We are not the customers. 

00:10:10.540 --> 00:10:14.615
 They are sold to companies - to business customers - 

00:10:14.620 --> 00:10:21.680
 who seek to maximize our value for their business, whatever it is. 

00:10:23.740 --> 00:10:27.020
 They use information from our faces, 

00:10:27.280 --> 00:10:32.360
 as we have given - billions upon billions of photos to Facebook, 

00:10:32.520 --> 00:10:35.480
 enabling them to train face recognition models. 

00:10:35.520 --> 00:10:39.440
 The models are then sold for military operations, 

00:10:39.440 --> 00:10:40.940
 certain of them in China. 

00:10:41.445 --> 00:10:43.965
 And the Chinese operations do many things, 

00:10:43.965 --> 00:10:46.525
 including the imprisonment of the Uighurs, 

00:10:46.960 --> 00:10:51.820
 a subgroup of the Uighur Muslim population in China, 

00:10:51.820 --> 00:10:56.800
 in what is rightly considered an open prison, 

00:10:57.440 --> 00:10:59.940
 where they don't actually have to put people behind bars, 

00:10:59.940 --> 00:11:03.860
 because they can constantly follow people with face recognition. 

00:11:06.215 --> 00:11:08.535
 The knowledge gained through our residual data, 

00:11:08.535 --> 00:11:10.295
 can be sold to anyone. 

00:11:10.425 --> 00:11:12.835
 For example, face recognition software, 

00:11:12.840 --> 00:11:15.260
 may be sold to a Chinese company, 

00:11:15.260 --> 00:11:17.760
 supporting the suppression of the Uighurs in China. 

00:11:18.220 --> 00:11:22.180
 Or that helps track down advocates for democracy in Hong Kong. 

00:11:22.840 --> 00:11:26.840
 That way, our precious family portraits can be used by Facebook, 

00:11:26.840 --> 00:11:29.840
 to facilitate authoritarian regimes. 

00:11:29.840 --> 00:11:32.720
 And we have a guarantee of our privacy. 

00:11:32.720 --> 00:11:35.060
 Because it's not our faces that are being sold, 

00:11:35.200 --> 00:11:37.920
 it is the residual data that is scraped by them. 

00:11:42.760 --> 00:11:46.100
 It is very difficult to understand this, 

00:11:46.105 --> 00:11:49.015
 for a very good reason. 

00:11:49.180 --> 00:11:51.640
 It's not because we're stupid, 

00:11:51.640 --> 00:11:56.920
 it is because these processes have been masked. 

00:11:57.600 --> 00:12:00.700
 They operate in secret. 

00:12:04.100 --> 00:12:08.700
 They are made in a way that they are incomprehensible, 

00:12:08.700 --> 00:12:13.020
 undetectable, to create ignorance, 

00:12:13.140 --> 00:12:15.340
 among the large group of us, 

00:12:15.340 --> 00:12:17.880
 which they call "users". 

00:12:19.300 --> 00:12:21.940
 Our ignorance is their bliss. 

00:12:26.920 --> 00:12:28.060
 These are some things, 

00:12:28.060 --> 00:12:32.380
 which has come to the public's knowledge. 

00:12:32.380 --> 00:12:38.320
 Facebook's massive scam experiments. 

00:12:38.480 --> 00:12:44.160
 This is where Facebook experimented with subliminal signals 

00:12:44.500 --> 00:12:47.120
 planted on the Facebook pages, 

00:12:47.600 --> 00:12:50.240
 that could actually affect 

00:12:50.240 --> 00:12:55.140
 behavior and emotions offline - in the real world. 

00:12:55.140 --> 00:12:58.035
 To find out if they could make people feel more happy or sad 

00:12:58.040 --> 00:13:00.260
 using subliminal signals, 

00:13:00.260 --> 00:13:04.720
 with language manipulations, word manipulations, etc. 

00:13:06.380 --> 00:13:10.460
 When those who performed the experiments described their work 

00:13:10.460 --> 00:13:17.880
 in the prestigious scientific journals that published their findings, 

00:13:17.880 --> 00:13:21.180
 highlighted the 2 key findings. 

00:13:21.400 --> 00:13:22.860
 Number 1: 

00:13:22.940 --> 00:13:24.860
 We know now, 

00:13:24.860 --> 00:13:27.400
 that we can manipulate 

00:13:27.400 --> 00:13:32.980
 subliminal signals in an online context, 

00:13:32.980 --> 00:13:38.860
 thus changing behavior or emotions in the real world. 

00:13:38.860 --> 00:13:41.820
 We know that we can succeed in doing this. 

00:13:42.540 --> 00:13:44.440
 Number 2: 

00:13:44.460 --> 00:13:47.935
 We can exercise this power 

00:13:47.935 --> 00:13:49.635
 - these methods - 

00:13:51.160 --> 00:13:56.160
 and at the same time bypassing users' consciousness. 

00:14:03.220 --> 00:14:07.280
 A large group of Pokemon Go players agree to a meeting in Leeuwarden. 

00:14:07.520 --> 00:14:10.800
 They go through the city together to catch as many Pokemon as possible. 

00:14:10.920 --> 00:14:15.460
 In the Netherlands alone there are 1.3 million. players 

00:14:15.800 --> 00:14:20.720
 A very interesting experiment occurs 

00:14:20.720 --> 00:14:25.120
 in the form of an AR game named Pokemon Go. 

00:14:25.220 --> 00:14:27.400
 In the game, you go around the real world. 

00:14:27.400 --> 00:14:32.680
 Pokémon are hiding in different places and you need to find them to pick them up. 

00:14:33.300 --> 00:14:34.700
 What are we not seeing, 

00:14:34.700 --> 00:14:38.880
 when Pokemon Go is introduced in our country? 

00:14:38.880 --> 00:14:43.160
 It's important to understand that Pokemon Go is an Augmented Reality game, 

00:14:43.160 --> 00:14:47.200
 that was incubated and developed at Google for many years. 

00:14:47.200 --> 00:14:51.580
 Google is the first pioneer in surveillance capitalism. 

00:14:51.580 --> 00:14:53.860
 The inventors of surveillance capitalism. 

00:14:54.480 --> 00:15:00.720
 Pokemon Go was invented at Google, incubated for many years, developed there, 

00:15:01.100 --> 00:15:03.860
 under the direction of a man named John Hanke, 

00:15:03.860 --> 00:15:08.980
 and John Hanke invented an operation called "Keyhole", 

00:15:08.980 --> 00:15:13.660
 that the CIA invested in, and later acquired by Google, 

00:15:13.820 --> 00:15:15.075
 called Google Earth. 

00:15:15.075 --> 00:15:18.135
 Was Google Earth a CIA start-up in the beginning? 

00:15:18.140 --> 00:15:24.440
 Yes. Google Earth was called Keyhole and it was a startup that the CIA invested in. 

00:15:25.020 --> 00:15:30.200
 It's important to understand that Pokemon Go wasn't just a fun little game, 

00:15:30.200 --> 00:15:34.020
 just sent out into the world 

00:15:34.020 --> 00:15:35.760
 by a toy company. 

00:15:37.600 --> 00:15:41.680
 When they decided to release Pokemon Go to the public, 

00:15:41.680 --> 00:15:44.440
 they would not publish it as a Google game. 

00:15:44.440 --> 00:15:48.380
 They sent it to the market like Niantic Labs that no one had heard of. 

00:15:48.860 --> 00:15:51.860
 It was just a cool start-up with a cool game. 

00:15:52.020 --> 00:15:56.140
 We now have this Google AR game, 

00:15:56.140 --> 00:15:57.640
 and it turns out, 

00:15:57.640 --> 00:16:02.240
 that the "big game" that sits at the top of the "small game", 

00:16:02.240 --> 00:16:03.660
 as the children play, 

00:16:04.000 --> 00:16:10.920
 is a game that accurately emulates the logic of surveillance capitalism. 

00:16:11.420 --> 00:16:16.980
 In surveillance capitalism, in the original version online, 

00:16:16.980 --> 00:16:19.280
 we predict the click-through rate, 

00:16:19.460 --> 00:16:22.860
 and we sell the click-through rate to the advertiser, 

00:16:22.900 --> 00:16:27.840
 who pay to get clicks on their website. 

00:16:28.120 --> 00:16:31.220
 Clicking-through all the way through to the Buy button. 

00:16:31.300 --> 00:16:32.880
 That's what they hope for. 

00:16:34.560 --> 00:16:36.680
 In the real world, 

00:16:37.700 --> 00:16:42.820
 paid business customers Niantic Labs 

00:16:43.040 --> 00:16:44.740
 - The Pokemon Go company - 

00:16:45.160 --> 00:16:47.900
 Niantic Labs paid for it, 

00:16:48.040 --> 00:16:53.620
 which in the real world equals click-through, 

00:16:53.760 --> 00:16:56.540
 which is called "foot-fall" 

00:16:57.685 --> 00:17:00.165
 To actually get real bodies, 

00:17:00.165 --> 00:17:02.460
 with their real feet, 

00:17:02.460 --> 00:17:05.700
 into real business, 

00:17:05.800 --> 00:17:10.680
 so that their feet say, "trip, trap, trip, trap" 

00:17:10.680 --> 00:17:12.980
 across the store 

00:17:12.980 --> 00:17:14.635
 or across the restaurant 

00:17:14.640 --> 00:17:16.820
 or across the bar, 

00:17:16.820 --> 00:17:20.320
 to buy something. 

00:17:20.345 --> 00:17:23.135
 So I could ask Niantic Labs 

00:17:23.135 --> 00:17:26.345
 about getting a Pokemon in my ice cream shop, for example. 

00:17:26.345 --> 00:17:29.185
 All these companies buy what is called 

00:17:29.185 --> 00:17:32.025
 - here's the term - 

00:17:32.145 --> 00:17:33.665
 "tricky modules" 

00:17:34.400 --> 00:17:40.660
 Modules there, just like a gemstone, lure people to you. 

00:17:41.100 --> 00:17:44.160
 Not that they can come and be happy, 

00:17:44.160 --> 00:17:48.620
 but then they come and spend money in your store or restaurant. 

00:17:48.620 --> 00:17:52.300
 Starbucks, McDonalds - they all made money. 

00:17:52.780 --> 00:17:54.700
 Everyone made money. 

00:17:54.700 --> 00:17:59.100
 Niantic Labs made money and all the companies made money. 

00:17:59.560 --> 00:18:02.455
 And those who played the game, 

00:18:02.460 --> 00:18:04.540
 had no idea. 

00:18:04.540 --> 00:18:07.980
 They used rewards and penalties in the game 

00:18:07.980 --> 00:18:12.180
 to rummage through the city, 

00:18:12.180 --> 00:18:16.720
 to the places that paid for your body. 

00:18:17.800 --> 00:18:21.100
 It was this that was the Pokemon Go game. 

00:18:21.100 --> 00:18:23.220
 This was the real game. 

00:18:23.300 --> 00:18:25.500
 A Game of Shadows. 

00:18:25.500 --> 00:18:28.415
 To get you somewhere, 

00:18:28.415 --> 00:18:31.625
 where we have predicted that you will be. 

00:18:32.340 --> 00:18:35.020
 Our predictions are increasing in value. 

00:18:35.220 --> 00:18:38.075
 If I can guarantee you will be there, 

00:18:38.075 --> 00:18:41.275
 my predictions are worth much more. 

00:18:41.825 --> 00:18:45.295
 Economics of action is the way I guarantee it. 

00:18:46.020 --> 00:18:50.480
 And Pokemon Go was a large-scale experiment 

00:18:50.620 --> 00:18:53.220
 - an experiment on a global scale - 

00:18:53.220 --> 00:18:55.580
 with economics of action, 

00:18:55.580 --> 00:19:00.580
 where with remote control automated behavior 

00:19:00.700 --> 00:19:02.920
 - manufactured behavior - 

00:19:02.920 --> 00:19:06.340
 to meet the commercial goals of others, 

00:19:06.340 --> 00:19:10.740
 all in while having fun. 

00:19:19.000 --> 00:19:20.720
 That is the intention, 

00:19:20.720 --> 00:19:25.060
 that you have the feeling of being served. 

00:19:25.820 --> 00:19:26.875
 That is the intention, 

00:19:26.875 --> 00:19:29.675
 that you become saturated with convenience, 

00:19:29.680 --> 00:19:32.260
 so you're not aware, 

00:19:32.260 --> 00:19:34.140
 so you don't complain, 

00:19:34.920 --> 00:19:40.520
 and this whole shadowing operation remains hidden 

00:19:40.520 --> 00:19:43.020
 because you are not asking questions. 

00:19:43.680 --> 00:19:46.780
 Because you are busy busy being entertained. 

00:19:51.480 --> 00:19:53.280
 It is no longer enough, 

00:19:53.280 --> 00:19:55.840
 to have what you do online, 

00:19:55.840 --> 00:19:59.240
 your browsing, your messages, your emails. 

00:19:59.240 --> 00:20:02.300
 We want to know about your walk in the park. 

00:20:02.535 --> 00:20:05.135
 We want to know what you are doing in your car. 

00:20:05.365 --> 00:20:08.865
 We want to know what you are doing in your home. 

00:20:09.520 --> 00:20:11.860
 "What if home security was different?" 

00:20:12.860 --> 00:20:13.860
 "What if it looked different?" 

00:20:22.675 --> 00:20:24.655
 After all, it's a beautiful system. 

00:20:26.280 --> 00:20:31.960
 Some kind of engineering engineer discovered, 

00:20:31.960 --> 00:20:34.680
 that the Nest security system 

00:20:34.840 --> 00:20:39.520
 has a microphone built in. 

00:20:40.460 --> 00:20:46.280
 That microphone does not appear in any floor plan. 

00:20:47.380 --> 00:20:48.960
 When you buy the security system, 

00:20:48.960 --> 00:20:52.280
 comes with a piece of paper that you fold out, 

00:20:52.280 --> 00:20:56.220
 who has a floor plan or you go online and find a floor plan, 

00:20:56.220 --> 00:20:57.980
 it does not display a microphone. 

00:20:58.680 --> 00:21:01.680
 It does not mention a microphone. 

00:21:02.540 --> 00:21:05.560
 Why should you have a microphone there? 

00:21:05.565 --> 00:21:08.575
 Remember what is our business? 

00:21:08.820 --> 00:21:12.720
 Our business depends on extraction 

00:21:12.720 --> 00:21:14.735
 of behavioral excess. 

00:21:14.740 --> 00:21:18.440
 Scale, scope and action. 

00:21:19.880 --> 00:21:25.560
 Are there better devices for extracting behavioral profits? 

00:21:25.560 --> 00:21:33.540
 Especially new forms: voices, conversations, what you see on TV, 

00:21:33.540 --> 00:21:36.340
 the music you listen to, 

00:21:36.580 --> 00:21:39.220
 who goes in and out of your home, 

00:21:39.220 --> 00:21:43.820
 if you yell at each other over breakfast. 

00:21:44.800 --> 00:21:49.080
 All this has tremendous predictive value. 

00:21:49.080 --> 00:21:53.740
 Voices are what everyone is looking for. Like they are looking for faces. 

00:21:54.240 --> 00:21:57.500
 So now it's public knowledge. 

00:21:57.500 --> 00:22:03.000
 There's a "Hey Google, what happens to put a microphone in your security system?" 

00:22:03.040 --> 00:22:07.160
 What does Google say? "Oops, sorry!" 

00:22:07.160 --> 00:22:10.260
 "Oh, we had no idea there was a microphone!" 

00:22:10.540 --> 00:22:16.780
 "Sorry, sorry. Someone put a microphone in, but we never intended to use it for anything." 

00:22:17.360 --> 00:22:19.340
 It's their business. 

00:22:20.140 --> 00:22:23.580
 To hide, to divert attention, 

00:22:24.100 --> 00:22:26.260
 to produce ignorance 

00:22:26.260 --> 00:22:31.120
 with mechanisms and methods that are undetectable and incomprehensible. 

00:22:31.120 --> 00:22:34.260
 And if they confront you with it, then deny it. 

00:22:34.260 --> 00:22:37.440
 Deny it as long as possible until they get used to it. 

00:22:37.980 --> 00:22:44.000
 If there is an element of it that you do not get used to, make an adjustment. 

00:22:44.000 --> 00:22:47.535
 "All right, we make sure all the microphones are ..." 

00:22:52.580 --> 00:22:56.060
 "off so they can't be used." 

00:22:56.060 --> 00:22:58.000
 And then "just wait .." 

00:22:58.000 --> 00:23:01.140
 when everyone is looking the other way 

00:23:01.140 --> 00:23:03.500
 is there a microphone in something else, 

00:23:03.860 --> 00:23:09.100
 there will be a microphone in the home device or in the music player, 

00:23:09.100 --> 00:23:13.160
 or whatever it may be. It will come again. 

00:23:16.040 --> 00:23:19.740
 "What if functionality was measured by 

00:23:19.760 --> 00:23:22.920
 that you never had to think about it? " 

00:23:26.160 --> 00:23:30.840
 There are two lawyers at the University of London, 

00:23:30.840 --> 00:23:33.880
 which has analyzed the privacy policy 

00:23:33.880 --> 00:23:35.520
 - how we consent - 

00:23:35.680 --> 00:23:37.900
 to these devices. 

00:23:39.880 --> 00:23:45.140
 They analyzed these documents for a single Nest Thermostat. 

00:23:45.140 --> 00:23:46.860
 What happens is, 

00:23:46.860 --> 00:23:49.920
 that the thermostat collects data, 

00:23:50.435 --> 00:23:53.475
 they send data to third parties, 

00:23:53.540 --> 00:23:57.520
 and the third parties pass on data to third parties, ad infinitum. 

00:23:57.520 --> 00:24:02.100
 An endless loop where your data goes wherever you go. 

00:24:03.120 --> 00:24:07.540
 No single company takes responsibility, 

00:24:07.540 --> 00:24:11.800
 for the third party they send your data to, 

00:24:11.800 --> 00:24:13.740
 uses your data to. 

00:24:13.980 --> 00:24:18.440
 Nest says, "If you don't want us to take your data, 

00:24:18.440 --> 00:24:22.640
 and you don't want us to pass them on to third parties, that's fine. 

00:24:23.040 --> 00:24:31.220
 But be aware that without your data, we will no longer support the functionality of your thermostat. " 

00:24:31.220 --> 00:24:34.260
 "We will no longer update your software." 

00:24:34.260 --> 00:24:39.260
 "Be aware that your smoke alarm may no longer work." 

00:24:39.460 --> 00:24:44.020
 "Be aware that your water pipes may freeze." 

00:24:44.020 --> 00:24:48.800
 So now the device's functionality is being held hostage, 

00:24:48.800 --> 00:24:51.900
 against the acceptance of the Privacy Agreement. 

00:24:52.820 --> 00:24:59.920
 And they say, "By the way, even if you accept, and we maintain the functionality, 

00:24:59.920 --> 00:25:02.880
 we send data to these third parties, 

00:25:02.880 --> 00:25:05.135
 and they use them as they see fit, 

00:25:05.140 --> 00:25:08.480
 without responsibility to us. 

00:25:09.840 --> 00:25:14.800
 The two forensic scientists conduct an analysis of a Nest thermostat, 

00:25:14.800 --> 00:25:17.100
 and their conclusion is, 

00:25:17.100 --> 00:25:19.600
 that based on the whole arrangement, 

00:25:19.600 --> 00:25:22.540
 any self-respecting consumer, 

00:25:22.540 --> 00:25:28.440
 anyone who is just a little vigilant about their spending habits, 

00:25:28.440 --> 00:25:38.200
 should judge at least 1000 privacy agreements, 

00:25:38.200 --> 00:25:41.860
 to install a single 

00:25:41.860 --> 00:25:45.220
 Nest thermostat in their home. 

00:25:45.820 --> 00:25:47.860
 "you have 3 minutes to go out ..." 

00:25:51.420 --> 00:25:53.480
 "What if you got more time?" 

00:25:55.480 --> 00:25:58.080
 "And what you really need from security systems ..." 

00:25:58.780 --> 00:26:00.600
 "... a sense of security." 

00:26:04.760 --> 00:26:07.960
 They are starting to extract data on a large scale. 

00:26:08.285 --> 00:26:11.265
 First, it's all you do online. 

00:26:11.265 --> 00:26:14.560
 And before long, they need more data. 

00:26:14.560 --> 00:26:17.335
 But they also discover, 

00:26:17.340 --> 00:26:19.480
 that they need many varieties of data. 

00:26:19.480 --> 00:26:24.540
 It is not just about quantity but about qualitatively different data. 

00:26:36.760 --> 00:26:42.940
 The problems with mobility are the same as those we saw online with smartphones: 

00:26:42.940 --> 00:26:46.560
 That you pay with your privacy without you realizing it. 

00:26:46.560 --> 00:26:49.555
 Because the car knows exactly what you're doing, where you're going, 

00:26:49.560 --> 00:26:52.540
 and all modern cars will have at least 15 cameras, 

00:26:52.540 --> 00:26:59.520
 and even if you only have access to 1% of all cars, you know what's happening around the world. 

00:27:01.740 --> 00:27:05.900
 If data is worth more than the cost of driving in the car, 

00:27:05.900 --> 00:27:10.520
 then you might get a free car. You just pay with your privacy, 

00:27:10.940 --> 00:27:16.360
 just as you pay with your privacy for all the free services you get from Google. 

00:27:20.280 --> 00:27:27.440
 When surveillance capitalism broke through in Silicon Valley - 2002, 2003 and 2004 - 

00:27:27.440 --> 00:27:30.560
 it changed the bar for investment. 

00:27:30.560 --> 00:27:37.240
 You now had Google making money from what I call the monitoring yield. 

00:27:38.460 --> 00:27:46.940
 What venture capitalist would invest in a company that just makes an app? 

00:27:46.940 --> 00:27:52.500
 When he can invest in a company that makes an app plus a monitoring dividend. 

00:27:52.500 --> 00:28:01.060
 So what immediately happened was that investments began to flow towards those who made the most money. 

00:28:01.060 --> 00:28:05.940
 And the increased earnings came from the monitoring yield. 

00:28:05.940 --> 00:28:11.500
 And this is now the structure that flows across the entire economy. 

00:28:11.500 --> 00:28:18.140
 Why spend energy on the engineers, factories, science, 

00:28:18.140 --> 00:28:21.045
 to make a car that runs without coal, 

00:28:21.045 --> 00:28:25.860
 when we only need to sell the data coming from the vehicles, 

00:28:25.900 --> 00:28:28.265
 and we have a monitoring yield, 

00:28:28.265 --> 00:28:31.295
 and the investors come to us, 

00:28:31.300 --> 00:28:35.860
 and gives us that kind of market capitalization, 

00:28:35.860 --> 00:28:38.540
 as the leading surveillance capitalists have. 

00:28:38.540 --> 00:28:40.440
 It's our new loan on life, 

00:28:40.440 --> 00:28:44.320
 it is the way forward in the 20th century. 

00:28:47.580 --> 00:28:50.340
 Monitoring data is valuable because everyone is demanding it. 

00:28:50.340 --> 00:28:53.135
 That's why Google wants their products in the cars, 

00:28:53.140 --> 00:28:55.880
 not to make money selling cars. 

00:28:59.360 --> 00:29:04.680
 You can use the car as a Trojan to collect all the data. 

00:29:07.180 --> 00:29:11.660
 We see it now ending the circle, back to the birthplace of mass production 

00:29:11.720 --> 00:29:13.900
 in the Ford factories, 

00:29:13.900 --> 00:29:21.080
 where Ford Motors CEO says: we want market capitalization just like Facebook and Google. 

00:29:21.080 --> 00:29:22.700
 How do we get it? 

00:29:22.700 --> 00:29:32.280
 Instead of making a car that runs without coal, we reuse our cars as surveillance vehicles, 

00:29:32.280 --> 00:29:38.440
 and then we stream data from the 100,000 people driving around in a Ford car. 

00:29:38.440 --> 00:29:41.320
 We combine it with the data we have from Ford Credit, 

00:29:41.320 --> 00:29:45.200
 where, as he says, we already know everything about you. 

00:29:45.200 --> 00:29:51.300
 And these data sets us on par with the big surveillance capitalists, 

00:29:51.300 --> 00:29:55.200
 and who wouldn't invest in Ford Motor in those circumstances? 

00:30:07.200 --> 00:30:10.640
 The primary economy - what we perceive as the primary economy - 

00:30:10.640 --> 00:30:15.320
 build a nice car, grow good food, build a house, 

00:30:15.320 --> 00:30:16.920
 means zero and nothing 

00:30:16.920 --> 00:30:19.240
 in this surveillance economy. 

00:30:19.240 --> 00:30:22.220
 This started with Android. 

00:30:22.220 --> 00:30:26.700
 When Google acquired the ability to make the Android phone, 

00:30:26.700 --> 00:30:28.380
 many people at Google said, 

00:30:28.380 --> 00:30:32.080
 it's great, now we have a phone just like Apple, 

00:30:32.080 --> 00:30:36.220
 and we can sell a phone and get a high margin to sell that phone, 

00:30:36.220 --> 00:30:42.100
 and that margin will give us profits and make us really rich. 

00:30:42.100 --> 00:30:46.580
 But the wiser heads at Google prevailed. 

00:30:46.580 --> 00:30:50.360
 Those who already understood surveillance capitalism prevailed. 

00:30:50.360 --> 00:30:52.940
 And they said the opposite: 

00:30:52.940 --> 00:31:00.100
 We want the phone and all accessories for the phone to be as cheap as possible. 

00:31:00.100 --> 00:31:04.040
 If we can get the price down to 0, then it's even better. 

00:31:04.040 --> 00:31:06.740
 We want everyone to have a phone. 

00:31:06.740 --> 00:31:12.280
 Because the more they have a phone and the more time they spend on a phone, 

00:31:12.280 --> 00:31:15.080
 the more data we get from them. 

00:31:15.080 --> 00:31:18.920
 The greater the surplus of behavior flows into our supply chains. 

00:31:18.920 --> 00:31:22.100
 So if we can give it away, we will give it away. 

00:31:24.280 --> 00:31:27.375
 Google free mobile operating system Android 

00:31:27.380 --> 00:31:32.860
 means Google has the keys to almost 90% of the world's smartphones. 

00:31:32.860 --> 00:31:36.740
 To collect as much data as possible from all these mobile phones 

00:31:36.740 --> 00:31:39.260
 Google experimented with network balloons 

00:31:39.260 --> 00:31:42.980
 in those parts of the world where mobile internet is not available. 

00:31:44.000 --> 00:31:49.120
 Facebook, which would not be left, flew network drones over emerging markets, 

00:31:49.120 --> 00:31:52.840
 and offered free internet in combination with a Facebook app. 

00:31:53.360 --> 00:31:59.480
 "... and connecting them presents one of the greatest opportunities for humanity today." 

00:32:01.200 --> 00:32:04.295
 "Hi Mark. Why are you showing such great interest in India?" 

00:32:04.295 --> 00:32:05.635
 "Answer honestly." 

00:32:06.880 --> 00:32:14.840
 "Our mission is to give everyone in the world the power to share what is important to them and to connect with all people in the world." 

00:32:15.560 --> 00:32:21.300
 With the possibility of US data robbery in mind, India politely declined the offer, 

00:32:21.300 --> 00:32:24.320
 and managed without Zuckerberg's generosity. 

00:32:24.720 --> 00:32:30.140
 In other parts of the world, Facebook's intentions are becoming more and more clear every day. 

00:32:30.140 --> 00:32:32.280
 But we need whistleblowers. 

00:32:32.780 --> 00:32:35.220
 Facebook would like to receive our data, 

00:32:35.220 --> 00:32:39.160
 but are not prepared to share information about how the business works. 

00:32:41.420 --> 00:32:46.580
 So here we have a document written by Facebook executives in Australia, 

00:32:46.720 --> 00:32:49.720
 and what they told their business customers there, 

00:32:49.720 --> 00:32:53.660
 was that we have so much data 

00:32:53.660 --> 00:33:01.680
 about 6.6 million Australian young adults and teens. 

00:33:01.680 --> 00:33:07.140
 As a result, we can predict mood swings, 

00:33:07.140 --> 00:33:10.720
 we can predict when they feel stressed, 

00:33:10.720 --> 00:33:12.120
 exhausted, 

00:33:12.120 --> 00:33:13.420
 tense, 

00:33:13.420 --> 00:33:15.220
 inferior, 

00:33:15.220 --> 00:33:16.540
 scared. 

00:33:17.680 --> 00:33:22.640
 All these kind of very personal feelings. 

00:33:22.640 --> 00:33:25.980
 And we can alert you 

00:33:25.980 --> 00:33:28.520
 at the exact moment, 

00:33:28.520 --> 00:33:32.840
 where they are most likely to need self-confidence. 

00:33:32.840 --> 00:33:40.300
 Let's say there is a young person who is considering a date this weekend, 

00:33:40.300 --> 00:33:43.940
 and it's Thursday night now and their excitement is peaking, 

00:33:43.940 --> 00:33:45.820
 and they need to boost their confidence. 

00:33:45.820 --> 00:33:49.480
 If you send them an ad for a sexy black leather jacket, 

00:33:49.480 --> 00:33:52.920
 send the ad right now. Offer them free delivery. 

00:33:52.920 --> 00:33:57.140
 Say it will be delivered to their door before waking up the next morning. 

00:33:57.145 --> 00:34:00.305
 Give them a discount coupon. 

00:34:00.795 --> 00:34:03.505
 Then you sell the black leather jacket. 

00:34:03.520 --> 00:34:04.540
 Do it now. 

00:34:04.540 --> 00:34:09.580
 We can tell you when the exact time when their vulnerability peaks. 

00:34:10.555 --> 00:34:12.505
 It is reality. 

00:34:12.815 --> 00:34:14.295
 It takes place. 

00:34:15.040 --> 00:34:17.540
 And if you don't believe me, 

00:34:17.540 --> 00:34:22.860
 you only need to rotate a few degrees, 

00:34:22.860 --> 00:34:26.380
 against something that happened in 2018. 

00:34:27.060 --> 00:34:28.260
 And what is it? 

00:34:28.760 --> 00:34:31.400
 It came from yet another whistleblower. 

00:34:31.735 --> 00:34:33.705
 His name was Chris Wylie. 

00:34:34.865 --> 00:34:37.725
 And he told us about Cambridge Analytica. 

00:34:40.960 --> 00:34:45.360
 Chris Wylie, a former employee of the British company Cambridge Analytica, 

00:34:45.360 --> 00:34:50.440
 sounded alarmed at the methods used by this political marketing company. 

00:34:50.440 --> 00:34:55.260
 Cambridge Analytica used Facebook data from more than $ 18 million Americans, 

00:34:55.260 --> 00:35:00.020
 to analyze the best way to tamper with American voters. 

00:35:01.000 --> 00:35:03.660
 One of the things Chris Wylie said, 

00:35:03.660 --> 00:35:07.380
 when he brought the story with The Guardian in 2018, 

00:35:08.220 --> 00:35:11.520
 was that we knew so much 

00:35:11.520 --> 00:35:14.620
 about so many individuals, 

00:35:15.300 --> 00:35:18.780
 that we could understand their inner demons, 

00:35:19.800 --> 00:35:23.640
 and we could figure out how to target their demons, 

00:35:23.640 --> 00:35:25.740
 how to address their fears, 

00:35:25.740 --> 00:35:27.680
 how to target their anger, 

00:35:27.680 --> 00:35:29.920
 how to target their paranoia. 

00:35:30.120 --> 00:35:35.760
 And with this targeting, we could trigger those feelings. 

00:35:35.760 --> 00:35:43.200
 And by triggering those feelings, we were able to manipulate them into clicking a website, 

00:35:43.200 --> 00:35:45.020
 join a group, 

00:35:45.480 --> 00:35:48.075
 tell them what to read, 

00:35:48.080 --> 00:35:51.240
 tell them what kind of people to hang out with, 

00:35:51.240 --> 00:35:53.320
 even telling them who to vote for. 

00:35:55.440 --> 00:36:01.300
 It's no different from Facebook at all 

00:36:01.300 --> 00:36:09.520
 tried to make out against the innocent young people in Australia and New Zealand. 

00:36:10.160 --> 00:36:12.975
 To target their inner demons 

00:36:12.975 --> 00:36:15.875
 - the same mechanisms, the same methods - 

00:36:15.880 --> 00:36:22.700
 only turned a few degrees from commercial to political results. 

00:36:22.700 --> 00:36:29.240
 Cambridge Analytica was nothing but a parasite on a huge host, 

00:36:29.980 --> 00:36:33.700
 and that host is surveillance capitalism. 

00:36:41.440 --> 00:36:45.540
 "Hi, Ella. I hope you find yourself right. 

00:36:46.320 --> 00:36:52.540
 You know how I always say: Everything you need you already have inside you. " 

00:36:54.880 --> 00:36:55.880
 "The truth is..." 

00:36:57.000 --> 00:36:59.780
 "... that's not all you can do for yourself." 

00:37:01.440 --> 00:37:03.680
 "We all need other people to reach our goals." 

00:37:05.575 --> 00:37:06.575
 "Ask yourself..." 

00:37:07.160 --> 00:37:08.820
 "... who you do it with." 

00:37:24.480 --> 00:37:26.380
 "Hi every one... 

00:37:26.380 --> 00:37:28.540
 Welcome to F8. 

00:37:28.540 --> 00:37:34.360
 Today we need to talk about building a privacy-oriented social platform. 

00:37:35.460 --> 00:37:37.300
 That's why I believe, 

00:37:37.700 --> 00:37:40.040
 that the future is private. 

00:37:41.340 --> 00:37:45.160
 So is everything all right, Professor Zuboff? 

00:37:46.520 --> 00:37:49.480
 In June 2019, 

00:37:49.480 --> 00:37:57.180
 just a few months after the big announcement that the future is private, 

00:37:57.180 --> 00:37:59.240
 there was a very interesting trial, 

00:37:59.240 --> 00:38:03.660
 brought before a California judge, 

00:38:03.660 --> 00:38:07.540
 and this lawsuit was a mass trial, 

00:38:07.540 --> 00:38:12.460
 brought by individuals who demanded to Facebook 

00:38:12.460 --> 00:38:18.460
 gave them the data that Facebook had made available 

00:38:18.480 --> 00:38:21.220
 for Cambridge Analytica, 

00:38:21.220 --> 00:38:26.500
 to find out if they had been targeted and tampered with by Cambridge Analytica. 

00:38:27.240 --> 00:38:32.520
 And that had to be decided by a California court. 

00:38:32.520 --> 00:38:38.060
 Facebook's attorneys leading the case, 

00:38:38.060 --> 00:38:41.400
 stood up in front of the judge and said, 

00:38:41.400 --> 00:38:44.160
 that any Facebook user, 

00:38:44.160 --> 00:38:49.160
 who use the platform and typically share information 

00:38:49.160 --> 00:38:52.880
 with 100 or more people in their network 

00:38:52.880 --> 00:38:55.080
 - once you've done it - 

00:38:55.080 --> 00:38:59.300
 then you cannot have an expectation of privacy, 

00:38:59.300 --> 00:39:08.460
 that allows you to assert any right of privacy, 

00:39:08.460 --> 00:39:14.120
 in a lawsuit like this, or in some other privacy-oriented lawsuit. 

00:39:14.120 --> 00:39:21.000
 So here we have again the public operation and the shadow operation. 

00:39:21.000 --> 00:39:27.340
 What happens behind the blanket is that a lawyer stands in front of a judge and says 

00:39:27.400 --> 00:39:32.340
 that no Facebook users can have any legitimate expectation of privacy. 

00:39:32.960 --> 00:39:36.340
 "This is the next chapter for our services." 

00:39:43.960 --> 00:39:46.980
 Do you use any Google products? 

00:39:47.500 --> 00:39:48.500
 No. 

00:39:49.640 --> 00:39:50.740
 How do you survive? 

00:39:52.015 --> 00:39:53.015
 Pretty good. 

00:39:53.360 --> 00:39:54.500
 If there is a reason, 

00:39:54.500 --> 00:39:57.660
 where I absolutely have a need to use Google, 

00:39:57.660 --> 00:40:03.080
 I go through different layers of encryption and change location settings, 

00:40:03.080 --> 00:40:04.960
 before I go to Google Search. 

00:40:04.960 --> 00:40:06.320
 For principle reasons. 

00:40:08.160 --> 00:40:12.340
 There is a way to avoid the ubiquitous eye of Google and Facebook. 

00:40:12.340 --> 00:40:18.100
 You can use a VPN and send all your data through a secure server in another country. 

00:40:18.140 --> 00:40:24.080
 But Big Tech doesn't lose the night's sleep over individuals who stand up against the surveillance capitalists. 

00:40:25.820 --> 00:40:32.600
 I don't want anyone to think that if they fail to use Google Search, they will fight the battle, 

00:40:32.600 --> 00:40:36.200
 because it is a collective problem that requires collective action. 

00:40:43.700 --> 00:40:49.580
 With us Amish, we depend on public transport for all distances. 

00:40:51.520 --> 00:40:54.860
 We travel locally on our slow way, 

00:40:54.860 --> 00:40:58.800
 and I think the horse and the horse-drawn carriage make us slow 

00:40:58.820 --> 00:41:02.220
 and contributes to the overall value we try to create and preserve, 

00:41:03.760 --> 00:41:05.860
 and let's not get carried away. 

00:41:14.860 --> 00:41:21.840
 A regular computer with security walls where you can't get to porn sites and the like ... 

00:41:22.080 --> 00:41:27.820
 ... with the shutdowns we have, it's totally shut down. 

00:41:28.260 --> 00:41:31.240
 Can you go online with this computer? 

00:41:31.240 --> 00:41:33.120
 No. Not at all. 

00:41:33.460 --> 00:41:38.640
 It will not play live pictures or music or anything like that. 

00:41:38.640 --> 00:41:41.540
 It is not a computer that is peeled apart. 

00:41:41.540 --> 00:41:44.100
 It is a computer built from the ground up in this way. 

00:41:44.780 --> 00:41:46.220
 Especially for you Amish? 

00:41:46.220 --> 00:41:47.020
 Yes. 

00:41:47.020 --> 00:41:49.640
 Want to show me your cell phone? 

00:41:49.640 --> 00:41:54.160
 Yes. All you can do with it is call. 

00:41:54.160 --> 00:41:57.140
 You can't send text messages or anything like that. 

00:41:57.140 --> 00:41:59.260
 It's just a laptop. 

00:41:59.260 --> 00:42:01.260
 So this is where it lies. 

00:42:01.260 --> 00:42:07.660
 When I go home, I don't have it with me. It's right here. It's for business. 

00:42:08.280 --> 00:42:14.440
 The technology is evolving so fast that it is difficult to handle. 

00:42:14.780 --> 00:42:19.220
 We have to teach what the moral impact is, 

00:42:19.220 --> 00:42:25.360
 and involve us so that each individual can make better choices on their own. 

00:42:30.520 --> 00:42:34.200
 We use technology as long as we use it, 

00:42:34.200 --> 00:42:37.120
 and we do not reach where technology is using us, 

00:42:37.120 --> 00:42:38.655
 and control us. 

00:42:38.655 --> 00:42:40.905
 That is what is the bottom line. 

00:42:42.900 --> 00:42:46.940
 It's strange about these people, 

00:42:46.940 --> 00:42:50.000
 as you might say living in the past, 

00:42:50.000 --> 00:42:51.820
 maybe they live in the future. 

00:42:52.245 --> 00:42:54.215
 It's only a moment ago 

00:42:55.380 --> 00:42:58.780
 we did not have many of these tools. 

00:43:01.040 --> 00:43:02.320
 We did fine. 

00:43:03.820 --> 00:43:06.540
 We lived rich and whole lives. 

00:43:06.540 --> 00:43:10.420
 We had close connections 

00:43:10.420 --> 00:43:12.360
 with friends and family. 

00:43:12.360 --> 00:43:13.400
 That said, 

00:43:13.620 --> 00:43:15.920
 then I will acknowledge, 

00:43:15.920 --> 00:43:19.395
 that there are many things that digital brings to our lives, 

00:43:19.395 --> 00:43:22.465
 and we deserve to have it all, 

00:43:23.240 --> 00:43:28.860
 but we deserve to have it, without having to pay the price of surveillance capitalism. 

00:43:29.680 --> 00:43:35.380
 Right now we are in a classic Faustian bargain. 

00:43:35.400 --> 00:43:40.980
 21st century citizens should not have to make the choice, 

00:43:40.980 --> 00:43:45.260
 between either being "analog" or 

00:43:45.260 --> 00:43:54.600
 live in a world where our self-determination and privacy are destroyed, 

00:43:54.600 --> 00:43:58.920
 for the sake of market logic. 

00:43:58.920 --> 00:44:00.620
 That is unacceptable. 

00:44:01.020 --> 00:44:04.840
 And we should not be naive either. 

00:44:04.840 --> 00:44:11.080
 If at some point you get the wrong people in the government, 

00:44:11.080 --> 00:44:16.780
 and they look over their shoulders at the abundant control options 

00:44:16.780 --> 00:44:19.160
 as these new systems present, 

00:44:19.160 --> 00:44:24.400
 then comes a time when - even in the West, even in our democratic society - 

00:44:24.400 --> 00:44:29.400
 our governments are tempted to annex these opportunities 

00:44:29.400 --> 00:44:32.200
 and use them over and against us. 

00:44:32.200 --> 00:44:34.300
 Let's not be naive about that. 

00:44:34.300 --> 00:44:39.440
 When we decide to oppose surveillance capitalism, 

00:44:39.440 --> 00:44:43.200
 right now while living in the market dynamics, 

00:44:43.200 --> 00:44:47.580
 we also preserve our democratic future 

00:44:47.580 --> 00:44:49.600
 and that kind of control and balancing 

00:44:49.600 --> 00:44:54.240
 that we need in the future in an information civilization, 

00:44:54.240 --> 00:44:59.360
 if we are to maintain freedom and democracy for another generation. 

00:44:59.860 --> 00:45:02.560
 The EU already has legislation, 

00:45:02.560 --> 00:45:06.940
 which it regularly uses to smash American tech companies. 

00:45:07.160 --> 00:45:12.860
 Google was fined several billion dollars for abusing their market monopoly. 

00:45:12.860 --> 00:45:24.380
 In theory, European citizens are protected from data theft by the competition rules and the GDPR (Data Protection Regulation). 

00:45:28.240 --> 00:45:34.920
 Do you think EU data protection legislation is a step in the right direction and is it sufficient? 

00:45:34.920 --> 00:45:42.220
 We have privacy laws, and GDPR is the forefront of our privacy laws, 

00:45:42.220 --> 00:45:44.680
 and we have antitrust laws. 

00:45:44.680 --> 00:45:46.720
 The thing is, 

00:45:46.720 --> 00:45:49.800
 however important the laws are, 

00:45:50.720 --> 00:45:53.560
 we still need more. 

00:45:53.560 --> 00:45:58.200
 Because surveillance capitalism has no precedent. 

00:45:58.620 --> 00:46:06.240
 So we are going to need legislation and regulations that directly correspond 

00:46:06.240 --> 00:46:10.960
 these new and unique companies. 

00:46:12.320 --> 00:46:16.340
 GDPR mentions data ownership, 

00:46:16.340 --> 00:46:19.580
 data availability and data portability. 

00:46:20.260 --> 00:46:23.100
 These are very important things, 

00:46:23.100 --> 00:46:28.780
 if the only data we are talking about is data in the public operation. 

00:46:29.120 --> 00:46:32.960
 The data we have provided to the company. 

00:46:32.960 --> 00:46:35.180
 But as we have seen, 

00:46:35.180 --> 00:46:38.080
 is most of the data used, 

00:46:38.080 --> 00:46:40.120
 which are fed into the factory, 

00:46:40.120 --> 00:46:41.820
 used to make the predictions, 

00:46:41.820 --> 00:46:45.380
 is data that we have not provided. 

00:46:45.380 --> 00:46:48.100
 Or if we've given them to us, then we don't even know. 

00:46:48.100 --> 00:46:53.600
 Because that data comes from our exclamation point, from the walk in the park, 

00:46:53.640 --> 00:46:58.940
 from capturing the cadence and the sound of our voices. 

00:46:58.940 --> 00:47:00.980
 All richly predictive signals. 

00:47:00.980 --> 00:47:10.380
 No matter how much ownership, availability or portability we claim, most data is only found in the shadow operation. 

00:47:10.380 --> 00:47:14.760
 And the shadow operation never shows up for us. 

00:47:14.760 --> 00:47:16.755
 We never get access to that data. 

00:47:16.760 --> 00:47:20.720
 They claim ownership over the data. 

00:47:20.720 --> 00:47:23.160
 They took them from our lives, 

00:47:23.160 --> 00:47:26.760
 they took them from our private experiences without our permission, 

00:47:26.760 --> 00:47:28.540
 the data analyzed, 

00:47:28.540 --> 00:47:32.880
 they turned it into products, sold them, and took the profits. 

00:47:32.880 --> 00:47:36.200
 Illegal profit. 

00:47:36.200 --> 00:47:41.560
 Because they took it from the beginning without asking, without our knowledge, 

00:47:41.560 --> 00:47:42.760
 - remember - 

00:47:42.760 --> 00:47:45.180
 by circumventing our consciousness. 

00:47:45.180 --> 00:47:51.560
 Does the EU have a chance against the giants of surveillance capitalism? 

00:47:51.560 --> 00:47:58.060
 These 20 years have been the wedding night of surveillance capitalism, 

00:47:58.060 --> 00:48:04.200
 because they have had 20 years without the law impeding obstacles. 

00:48:04.200 --> 00:48:07.280
 Without the law having put obstacles in the way. Why? 

00:48:08.220 --> 00:48:12.680
 The main reason is that they do things that have never been done before. 

00:48:12.680 --> 00:48:14.980
 So there are no laws that forbid it. 

00:48:15.660 --> 00:48:21.200
 Like factories like employed children, 

00:48:22.160 --> 00:48:25.560
 in a mass-making business, 

00:48:25.560 --> 00:48:27.980
 there had never been anything like it, 

00:48:27.980 --> 00:48:30.200
 and there were no laws prohibiting it, 

00:48:30.260 --> 00:48:33.540
 and it took our community a while before they woke up. 

00:48:33.980 --> 00:48:40.740
 We resisted the mining industry and their acts of violence, 

00:48:40.740 --> 00:48:43.560
 the companies that we know from "The Gilded Age". 

00:48:43.920 --> 00:48:48.980
 The companies that we turned to, us whose leaders we called robber barons. 

00:48:49.760 --> 00:48:52.440
 They were not called that in their time. 

00:48:52.440 --> 00:49:06.200
 Back then, they were worshiped as wealthy gods, geniuses who knew how to make use of the power of machines and capital. 

00:49:06.200 --> 00:49:13.380
 If we had tried to stop it, to restrict it, to make it illegal, 

00:49:13.380 --> 00:49:17.640
 in each of those 20 years, and we had failed completely, 

00:49:17.640 --> 00:49:24.500
 then maybe I would support my head and think "it's all bad," 

00:49:24.500 --> 00:49:26.040
 but that's not it at all, 

00:49:26.040 --> 00:49:29.040
 we haven't tried to stop it at all yet. 

00:49:30.660 --> 00:49:35.040
 Surveillance capitalism is 20 years old. 

00:49:35.040 --> 00:49:38.140
 Democracy is hundreds of years old. 

00:49:38.140 --> 00:49:39.820
 I put my money on democracy. 

