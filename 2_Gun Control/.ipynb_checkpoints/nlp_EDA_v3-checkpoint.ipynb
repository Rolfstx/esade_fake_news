{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgOfB_vDWqh_"
   },
   "source": [
    "useful resource: https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 37581,
     "status": "ok",
     "timestamp": 1593358430881,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "SQj59oQbWkkl",
    "outputId": "37c3ba27-1634-43c6-b11f-6c0cb571a271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#code needed to use colab notebook\n",
    "#if you're using juptyer notebook then skip this line\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zz3uL5NwKvYF"
   },
   "source": [
    "## these modules need to be installed before starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42203,
     "status": "ok",
     "timestamp": 1593358435715,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "ythTOThCbWJV",
    "outputId": "f276d3c7-0fc1-4b31-acec-da155f14cb5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chart_studio\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/ce/330794a6b6ca4b9182c38fc69dd2a9cbff60fd49421cb8648ee5fee352dc/chart_studio-1.1.0-py3-none-any.whl (64kB)\n",
      "Requirement already satisfied: six in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from chart_studio) (1.12.0)\n",
      "Requirement already satisfied: requests in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from chart_studio) (2.22.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from chart_studio) (1.3.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from chart_studio) (4.2.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from requests->chart_studio) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from requests->chart_studio) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from requests->chart_studio) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from requests->chart_studio) (3.0.4)\n",
      "Installing collected packages: chart-studio\n",
      "Successfully installed chart-studio-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chart_studio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47886,
     "status": "ok",
     "timestamp": 1593358441447,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "egSY77-fbbgH",
    "outputId": "b1a65d33-4e85-4b4e-bbef-ca2a36e22d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scattertext\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/43/b7fe555bff000ade599c8e67e951f548abc5f5c5d1aaf3d503cdd297bd35/scattertext-0.0.2.65-py3-none-any.whl (7.2MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from scattertext) (1.16.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from scattertext) (1.2.1)\n",
      "Requirement already satisfied: mock in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from scattertext) (3.0.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from scattertext) (0.24.2)\n",
      "Requirement already satisfied: six in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from scattertext) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from scattertext) (0.21.2)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from scattertext) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from pandas->scattertext) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from pandas->scattertext) (2.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from scikit-learn->scattertext) (0.13.2)\n",
      "Requirement already satisfied: patsy>=0.4.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from statsmodels->scattertext) (0.5.1)\n",
      "Installing collected packages: scattertext\n",
      "Successfully installed scattertext-0.0.2.65\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scattertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52511,
     "status": "ok",
     "timestamp": 1593358446102,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "PM30CA8fJ_2V",
    "outputId": "95b583d1-6978-4d64-c1b5-8464a0432293"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atryf\\Anaconda3\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl (636kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from textblob) (3.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cufflinks\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/18/4d32edaaf31ba4af9745dac676c4a28c48d3fc539000c29e855bd8db3b86/cufflinks-0.17.3.tar.gz (81kB)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from cufflinks) (1.16.4)\n",
      "Requirement already satisfied: pandas>=0.19.2 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from cufflinks) (0.24.2)\n",
      "Requirement already satisfied: plotly>=4.1.1 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from cufflinks) (4.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from cufflinks) (1.12.0)\n",
      "Collecting colorlover>=0.2.1 (from cufflinks)\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/53/f696e4480b1d1de3b1523991dea71cf417c8b19fe70c704da164f3f90972/colorlover-0.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=34.4.1 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from cufflinks) (41.0.1)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from cufflinks) (7.6.1)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from cufflinks) (7.5.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from pandas>=0.19.2->cufflinks) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from pandas>=0.19.2->cufflinks) (2.8.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from plotly>=4.1.1->cufflinks) (1.3.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (4.3.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (2.0.9)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.4.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (4.4.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (2.4.2)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.13.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (5.1.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (4.4.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (3.5.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython>=5.3.0->cufflinks) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.3.0->cufflinks) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.3.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=5.3.0->cufflinks) (0.5.0)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (6.0.3)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (5.3.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (3.0.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (4.5.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (6.0.0)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (18.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (0.14.11)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (2.10.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.8.2)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.7.1)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (5.5.0)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.1.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (3.1.0)\n",
      "Requirement already satisfied: testpath in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.4.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.4.2)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.6.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.3)\n",
      "Requirement already satisfied: mistune>=0.8.1 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.8.4)\n",
      "Requirement already satisfied: webencodings in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.5.1)\n",
      "Building wheels for collected packages: cufflinks\n",
      "  Building wheel for cufflinks (setup.py): started\n",
      "  Building wheel for cufflinks (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\atryf\\AppData\\Local\\pip\\Cache\\wheels\\7d\\ba\\8d\\38b672c3e40d8bd22dd60b8e6e29965b43f2b4be4d064e44d5\n",
      "Successfully built cufflinks\n",
      "Installing collected packages: colorlover, cufflinks\n",
      "Successfully installed colorlover-0.3.0 cufflinks-0.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cufflinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/92/f4380cf87495c9d5039adbff4980af457d48a6a1932276f15c02cd8fc183/spacy-2.3.0-cp37-cp37m-win_amd64.whl (9.4MB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/f3/76/4697ce203a3d42b2ead61127b35e5fcc26bba9a35c03b32a2bd342a4c869/tqdm-4.46.1-py2.py3-none-any.whl (63kB)\n",
      "Collecting blis<0.5.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/7e/1981d5389b75543f950026de40a9d346e2aec7e860b2800e54e65bd46c06/blis-0.4.1-cp37-cp37m-win_amd64.whl (5.0MB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/5a/0d1b575ed40989d74fab25723083837c220246b25f3582917135cb32453f/preshed-3.0.2-cp37-cp37m-win_amd64.whl (105kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from spacy) (41.0.1)\n",
      "Collecting srsly<1.1.0,>=1.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/31/edaf3cdb7fcb644a51c7a568bc62a8c8d7462e61fa79b090f4d12d73d39e/srsly-1.0.2-cp37-cp37m-win_amd64.whl (179kB)\n",
      "Collecting thinc==7.4.1 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/8b/6f/7cd666630afeb9b85cbd23c75da76b61580e45a9fe1c19145e3f7675ffc8/thinc-7.4.1-cp37-cp37m-win_amd64.whl (2.0MB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from spacy) (1.16.4)\n",
      "Collecting catalogue<1.1.0,>=0.0.7 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Collecting plac<1.2.0,>=0.9.6 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/84/d1/35eab0c8cc9fd9432becaf3e90144762b3201a45079e62c47a8ae8739763/cymem-2.0.3-cp37-cp37m-win_amd64.whl\n",
      "Collecting wasabi<1.1.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/04/e5/aa1892776a8ed6f6d552ba1be0640e6403f07e850d36e79f475f1e605aa9/wasabi-0.7.0.tar.gz\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/7b/d77bc9bb101e113884b2d70a118e7ec8dcc9846a35a0e10d47ca37acdcbf/murmurhash-1.0.2-cp37-cp37m-win_amd64.whl\n",
      "Collecting importlib-metadata>=0.20; python_version < \"3.8\" (from catalogue<1.1.0,>=0.0.7->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/58/cdea07eb51fc2b906db0968a94700866fc46249bdc75cac23f9d13168929/importlib_metadata-1.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\atryf\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.5.1)\n",
      "Building wheels for collected packages: wasabi\n",
      "  Building wheel for wasabi (setup.py): started\n",
      "  Building wheel for wasabi (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\atryf\\AppData\\Local\\pip\\Cache\\wheels\\33\\96\\74\\01741d5dde3d866a4461a05b3fc6aa43bd7ece8729a7264bf7\n",
      "Successfully built wasabi\n",
      "Installing collected packages: tqdm, blis, cymem, murmurhash, preshed, srsly, importlib-metadata, catalogue, plac, wasabi, thinc, spacy\n",
      "  Found existing installation: tqdm 4.32.1\n",
      "    Uninstalling tqdm-4.32.1:\n",
      "      Successfully uninstalled tqdm-4.32.1\n",
      "  Found existing installation: importlib-metadata 0.17\n",
      "    Uninstalling importlib-metadata-0.17:\n",
      "      Successfully uninstalled importlib-metadata-0.17\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 importlib-metadata-1.7.0 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.3.0 srsly-1.0.2 thinc-7.4.1 tqdm-4.46.1 wasabi-0.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python was not found but can be installed from the Microsoft Store: https://go.microsoft.com/fwlink?linkID=2082640\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56808,
     "status": "ok",
     "timestamp": 1593358450439,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "Cr6DJLqLJ_2Z",
    "outputId": "68c593bb-0eb6-4f37-9aba-31909fb553ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1003\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1003\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1003\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1003' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1003\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1003\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1003\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1003' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1003\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'en_core_web_sm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-37761b1ce7c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;31m#nlp = spacy.load('en_core_web_md')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'en_core_web_sm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 6.0)\n",
    "import plotly.graph_objs as go\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks\n",
    "pd.options.display.max_columns = 30\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "from collections import Counter\n",
    "import scattertext as st\n",
    "import spacy\n",
    "from pprint import pprint\n",
    "import en_core_web_sm\n",
    "#nlp = spacy.load('en_core_web_md')\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58723,
     "status": "ok",
     "timestamp": 1593358452392,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "akqnEf1QW8MX",
    "outputId": "a552f260-b72b-474a-8780-3bc2d00965ec"
   },
   "outputs": [],
   "source": [
    "%cd \"gdrive/My Drive/Colab Notebooks\"\n",
    "#%cd ..\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59170,
     "status": "ok",
     "timestamp": 1593358453096,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "1bckhI00XL8k",
    "outputId": "59b542f3-e966-4131-b29f-c59a99f25afa"
   },
   "outputs": [],
   "source": [
    "# load train_cleaned.csv\n",
    "filename = \"20200625-155513_gun_control_nlp_subs_clean.csv\"\n",
    "df = pd.read_csv(filename, index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2IkLL8QON8e"
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57098,
     "status": "ok",
     "timestamp": 1593358453101,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "oLA7FeFIW8QK",
    "outputId": "c6f82efe-e1a0-47ea-ac11-92965ddc54b6"
   },
   "outputs": [],
   "source": [
    "#calculate number of characters\n",
    "df['review_len'] = df['text'].astype(str).apply(len)\n",
    "\n",
    "#calculate number of words\n",
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56641,
     "status": "ok",
     "timestamp": 1593358453110,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "oDn56y6KON8k",
    "outputId": "75db6f68-62bf-496f-8617-85621b23c9cb"
   },
   "outputs": [],
   "source": [
    "#average number of characters by bias\n",
    "\n",
    "df.groupby('Bias_num').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56660,
     "status": "ok",
     "timestamp": 1593358453619,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "PwzJdc39Yqks",
    "outputId": "8f21fb69-7a5c-4943-bf0f-763358008fbd"
   },
   "outputs": [],
   "source": [
    "plt.hist(df['review_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55980,
     "status": "ok",
     "timestamp": 1593358453625,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "_wUr1PqQbpBX",
    "outputId": "be302621-506b-45f2-e87e-7b0e609506cb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df['word_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53614,
     "status": "ok",
     "timestamp": 1593358454481,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "RtLRdzXBcyOQ",
    "outputId": "e71263da-f79b-4a1b-e6d9-c77440462a29"
   },
   "outputs": [],
   "source": [
    "x1 = df.loc[df['Bias_num'] == 1, 'word_count']\n",
    "x0 = df.loc[df['Bias_num'] == 0, 'word_count']\n",
    "\n",
    "trace1 = go.Histogram(\n",
    "    x=x0, name='Left',\n",
    "    opacity=0.75\n",
    ")\n",
    "trace2 = go.Histogram(\n",
    "    x=x1, name = 'Right',\n",
    "    opacity=0.75\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(barmode='overlay', title='Distribution of word count based on bias')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7652,
     "status": "ok",
     "timestamp": 1593285746627,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "sSO0H063dfeq",
    "outputId": "bf41f257-8d6b-4863-98d6-ea356be62ae1"
   },
   "outputs": [],
   "source": [
    "x1 = df.loc[df['Bias_num'] == 1, 'review_len']\n",
    "x0 = df.loc[df['Bias_num'] == 0, 'review_len']\n",
    "\n",
    "trace1 = go.Histogram(\n",
    "    x=x0, name='Left',\n",
    "    opacity=0.75\n",
    ")\n",
    "trace2 = go.Histogram(\n",
    "    x=x1, name = 'Right',\n",
    "    opacity=0.75\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(barmode='overlay', title='Number of characters in subtitley by bias')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JbI_UwWON83"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uHM6rBSHJ_22"
   },
   "source": [
    "## The distribution of top unigrams before removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6999,
     "status": "ok",
     "timestamp": 1593285746633,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "GUCzCTXBJ_22",
    "outputId": "cffb945a-0507-44f1-d058-06079ecf7adf"
   },
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(df['text'], 20)\n",
    "df1 = pd.DataFrame(common_words, columns = ['text' , 'count'])\n",
    "df1\n",
    "df1.groupby('text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 words in review before removing stop words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-k9yMsHJ_27"
   },
   "source": [
    "## The distribution of top unigrams after removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6403,
     "status": "ok",
     "timestamp": 1593285747057,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "mCEAs3XpJ_27",
    "outputId": "3e814fb5-b487-4f59-c751-e9d0e0d70d92"
   },
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(df['text'], 20)\n",
    "df2 = pd.DataFrame(common_words, columns = ['text' , 'count'])\n",
    "df2\n",
    "df2.groupby('text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 words in review after removing stop words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKNVe2fvJ_2-"
   },
   "source": [
    "## The distribution of top bigrams before removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7171,
     "status": "ok",
     "timestamp": 1593285748233,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "OysVDEZMJ_2_",
    "outputId": "d18b8b51-5eed-4c87-f764-a989e382c452"
   },
   "outputs": [],
   "source": [
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_bigram(df['text'], 20)\n",
    "df3 = pd.DataFrame(common_words, columns = ['text' , 'count'])\n",
    "df3\n",
    "df3.groupby('text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 bigrams in review before removing stop words')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aK-QUPFfJ_3C"
   },
   "source": [
    "## The distribution of top bigrams after removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7335,
     "status": "ok",
     "timestamp": 1593285748800,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "hg5_1i2yJ_3C",
    "outputId": "52aa6bc8-9bf1-4a4e-97ff-1e767002672e"
   },
   "outputs": [],
   "source": [
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_bigram(df['text'], 20)\n",
    "df4 = pd.DataFrame(common_words, columns = ['text' , 'count'])\n",
    "df4\n",
    "df4.groupby('text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 bigrams in review after removing stop words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJ86gGzGJ_3F"
   },
   "source": [
    "## The distribution of Top trigrams before removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7964,
     "status": "ok",
     "timestamp": 1593285750584,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "CblcUc--J_3G",
    "outputId": "d5702311-8291-4528-f6c1-b99283d17ee1"
   },
   "outputs": [],
   "source": [
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(df['text'], 20)\n",
    "df5 = pd.DataFrame(common_words, columns = ['text' , 'count'])\n",
    "df5\n",
    "df5.groupby('text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 trigrams in review before removing stop words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0JHwzIISJ_3I"
   },
   "source": [
    "## The distribution of Top trigrams after removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7912,
     "status": "ok",
     "timestamp": 1593285751076,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "PRx1LsRkJ_3J",
    "outputId": "957efa6c-f857-4cc4-d6ca-66c75d7a3dab",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(df['text'], 20)\n",
    "df6 = pd.DataFrame(common_words, columns = ['text' , 'count'])\n",
    "#df6\n",
    "df6.groupby('text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 trigrams in review after removing stop words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G3SarLRbON9d"
   },
   "source": [
    "## Find top trigrams after removing stop words for RIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7197,
     "status": "ok",
     "timestamp": 1593285751078,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "USMs8bawON9e",
    "outputId": "75a8c2cb-4749-4e5c-c192-11bbcb879fde"
   },
   "outputs": [],
   "source": [
    "#create df with only right subtitles\n",
    "right = df[df['Bias_num']==1]\n",
    "right.head(1)\n",
    "\n",
    "#create df with only left subtitles\n",
    "left = df[df['Bias_num']==0]\n",
    "left.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6317,
     "status": "ok",
     "timestamp": 1593285751629,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "t_2rwK4yON9j",
    "outputId": "084dc8c8-39a0-42f1-925c-0baacf92e37c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#right wing trigram\n",
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(right['text'], 20)\n",
    "df6 = pd.DataFrame(common_words, columns = ['text' , 'count'])\n",
    "#df6\n",
    "df6.groupby('text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', \n",
    "    title='Top 20 trigrams for RIGHT wing media in subtitles after removing stop words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6907,
     "status": "ok",
     "timestamp": 1593285752387,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "9Iv3yeCxON9p",
    "outputId": "fa1f5ff7-c97a-4acf-f4f4-68ff743b1c74"
   },
   "outputs": [],
   "source": [
    "#LEFT wing trigram\n",
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(left['text'], 20)\n",
    "df6 = pd.DataFrame(common_words, columns = ['text' , 'count'])\n",
    "#df6\n",
    "df6.groupby('text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', \n",
    "    title='Top 20 trigrams for LEFT wing media in subtitles after removing stop words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "syXgraoWJ_3M"
   },
   "source": [
    "## Finding characteristic terms and their associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5837,
     "status": "ok",
     "timestamp": 1593285752389,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "IvQbvjNvV993",
    "outputId": "e2318ed9-e944-47d9-ce9b-93d6f11134ed"
   },
   "outputs": [],
   "source": [
    "#convert Bias_num to string\n",
    "df_corpus = df.copy()\n",
    "df_corpus['Bias_num'] = df_corpus['Bias_num'].apply(str)\n",
    "df_corpus.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5597,
     "status": "ok",
     "timestamp": 1593285752390,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "TGpcy7u5Xeb2",
    "outputId": "02cd3d34-1e45-40e9-acd3-00b292e3f5ec"
   },
   "outputs": [],
   "source": [
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71933,
     "status": "ok",
     "timestamp": 1593285818972,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "E3Js0zp6J_3M",
    "outputId": "fbb52bc5-9851-4ff4-f403-75ef9076d32e"
   },
   "outputs": [],
   "source": [
    "#Following are the terms that differentiate the review text from a general English corpus.\n",
    "corpus = st.CorpusFromPandas(df_corpus, category_col='Bias_num', text_col='text', nlp=nlp).build()\n",
    "print(list(corpus.get_scaled_f_scores_vs_background().index[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71680,
     "status": "ok",
     "timestamp": 1593285818974,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "sF4fvw9RJ_3P",
    "outputId": "fa4092f0-cf66-445d-8ac4-87390bfd97cd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Following are the terms in review text that are most associated with right wing channels:\n",
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['Right score'] = corpus.get_scaled_f_scores(\"1\")\n",
    "pprint(list(term_freq_df.sort_values(by='Right score', ascending=False).index[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 69699,
     "status": "ok",
     "timestamp": 1593285818975,
     "user": {
      "displayName": "Andreas Tryfonos",
      "photoUrl": "",
      "userId": "02874545524961049688"
     },
     "user_tz": -180
    },
    "id": "oryzwEQsJ_3S",
    "outputId": "aa5538ae-1f9a-40c9-97c3-d8f08f08ffba"
   },
   "outputs": [],
   "source": [
    "#Following are the terms in review text that are most associated with left wing channels:\n",
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['Left score'] = corpus.get_scaled_f_scores(\"0\")\n",
    "pprint(list(term_freq_df.sort_values(by='Left score', ascending=False).index[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrfUy3jMJ_38"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nlp_EDA_v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
