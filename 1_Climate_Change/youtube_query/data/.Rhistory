library(data.table)
#load dataset
#unique video dataset or all videos dataset
df = fread("~/Documents/GitHub/esade_fake_news/4_Climate_Change/youtube_query/data/20200507-033205_climate_change.csv")
#load dataset
#unique video dataset or all videos dataset
df = fread("~/Documents/GitHub/esade_fake_news/4_Climate_Change/youtube_query/data/20200507-033205_climate_change.csv")
setwd("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data")
#load dataset
#unique video dataset or all videos dataset
df = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/20200507-033205_climate_change.csv")
#groupby genre and count number of videos
genre = df[, .N, by='genre']
#groupby channel and count number of channels
channel = df[, unique(channel), by='genre']
channel2 = channel[, .N, by='genre']
#merge genre and channel2
genre_channel = merge(genre,
channel2,
by='genre',
suffixes= c('.video', '.channel'))[order(-N.video)]
#export genre_channel. Then label relevant genres with 1 in excel
write.csv(genre_channel, "~/Documents/GitHub/esade_fake_news/4_Politics/python3_script/data/genre/20200507-033205_climate_change_genre.csv", row.names=FALSE)
#export genre_channel. Then label relevant genres with 1 in excel
write.csv(genre_channel, "~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/genre/20200507-033205_climate_change_genre.csv", row.names=FALSE)
#import genre_channel with added relevant column
genre_relevant = fread("~/Documents/GitHub/esade_fake_news/4_Politics/python3_script/data/genre/20200504-193926_joe_biden_genre_channel.csv")
#import genre_channel with added relevant column
genre_relevant = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/genre/20200507-033205_climate_change_genre.csv")
#merge datasets to obtain relevant videos.
df2 = merge(df,
genre_relevant,
by='genre')
# 75% of videos are relevant
mean(df2$relevant)
head(df2)
# 75% of videos are relevant
mean(df2$relevant)
#create new dataset with only relevant videos
df_relevant = df2[relevant==1]
#create dataset with only channel and count.
df_relevant_channel = df_relevant[, .N, by='channel'][order(channel)]
#import genre_channel with added relevant column
genre_relevant = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/genre/20200507-033205_climate_change_genre.csv")
#merge datasets to obtain relevant videos.
df2 = merge(df,
genre_relevant,
by='genre')
head(df2)
# 75% of videos are relevant
mean(df2$relevant)
#create new dataset with only relevant videos
df_relevant = df2[relevant==1]
#import genre_channel with added relevant column
genre_relevant = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/genre/20200507-033205_climate_change_genre.csv")
#merge datasets to obtain relevant videos.
df2 = merge(df,
genre_relevant,
by='genre')
#import genre_channel with added relevant column
genre_relevant = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/genre/20200507-033205_climate_change_genre.csv")
#merge datasets to obtain relevant videos.
df2 = merge(df,
genre_relevant,
by='genre')
head(df2)
# 75% of videos are relevant
mean(df2$relevant)
#create new dataset with only relevant videos
df_relevant = df2[relevant==1]
#create dataset with only channel and count.
df_relevant_channel = df_relevant[, .N, by='channel'][order(channel)]
#load cleaned channel dataset
df_updated = fread("~/Documents/GitHub/esade_fake_news/4_Politics/python3_script/data/channels/20200504-193926_joe_biden_channels_relevant.csv", na.strings=c("","NA"), drop=c('Column1'))
#load media bias dataset
media_bias = fread("~/Documents/GitHub/esade_fake_news/4_Politics/python3_script/data/channels/media_bias_data.csv", drop='Website')
#merge cleaned channel dataset with media bias
df_merged = merge(df_updated,
media_bias,
by.x='media_bias',
by.y='News Source')
#remove N column
df_merged[, 'N':=NULL]
#complete dataset
df_merged2 = merge(df_relevant,
df_merged,
by='channel')
# % of videos still present in raw dataset.
nrow(df_merged2) / nrow(df)
#table with count and percentage
tblFun <- function(x){
tbl <- table(x)
res <- cbind(tbl,round(prop.table(tbl)*100,2))
colnames(res) <- c('Count','Percentage')
res
}
#
group_by_bias = do.call(rbind,lapply(df_merged2[, 'Bias'],tblFun))
group_by_bias
#convert Bias into binary
#right = 1
#left = 0
mapping <- c("Left" = 0, "Left-Center" = 0,
"Least Biased" = 1, "Right" = 1, "Right-Center" = 1)
df_merged2$Bias_num <- mapping[df_merged2$Bias]
#keep columns title, description and Bias_num for NLP dataset
df_nlp = df_merged2[, c('Bias_num' ,'title', 'description', 'channel','id')]
# 32% Bias_num is 1, 68% is 0
sum(df_nlp$Bias_num) / nrow(df_nlp)
write.csv(df_relevant_channel, "~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels.csv")
#load media bias dataset
media_bias = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/media_bias_data.csv", drop='Website')
#load cleaned channel dataset
df_updated = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels.csv", na.strings=c("","NA"), drop=c('Column1'))
#load cleaned channel dataset
df_updated = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels.csv", na.strings=c("","NA"))
#merge cleaned channel dataset with media bias
df_merged = merge(df_updated,
media_bias,
by.x='media_bias',
by.y='News Source')
fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels.csv", na.strings=c("","NA"))
fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels.csv", na.strings=c("","NA"))
fread("~/Documents/GitHub/esade_fake_news/4_Politics/python3_script/data/channels/20200504-193926_joe_biden_channels_relevant.csv", na.strings=c("","NA"), drop=c('Column1'))
test_data = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels.csv", na.strings=c("","NA"))
test_channel = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/media_bias_data.csv", drop='Website')
test_channel[,.("News Source")]
test_channel[,.("News Source")]
test_channel[,"News Source"]
news_source = test_channel[,"News Source"]
news_source2 <- data.frame(news_source , news_source )
news_source2
head(news_source2)
news_source = test_channel[,"News Source"]
media_bias = news_source
news_source2 <- data.frame(news_source , media_bias)
head(news_source2)
news_source2 <- data.frame(news_source , media_bias)
head(news_source2)
news_source2 <- data.frame(news_source, news_source)
head(news_source2)
test_data
merge(test_data, news_source2, by.x = channel, by.y = news_source, all.x = TRUE)
merge(test_data, news_source2, by.x = channel, by.y = news_source, all.x = TRUE)
merge
?merge
View(genre_relevant)
merge(test_data, news_source2, by.x = channel, by.y = news_source, all.x = TRUE)
merge(test_data, news_source2, by.x = channel, by.y = news_source)
merge(test_data, news_source2, by.x = channel, by.y = news_source, all.x = TRUE)
merge(test_data, news_source2, by.x = channel, by.y = news_source, all.x = TRUE)
news_source2 <- data.frame(news_source, news_source)
colnames(news_source2) <- c("news_source", "news_source2")
head(news_source2)
merge(test_data, news_source2, by.x = channel, by.y = news_source2, all.x = TRUE)
test_data
colnames(news_source2) <- c("channel", "news_source")
head(news_source2)
merge(test_data, news_source2, by.x = channel, by.y = channel, all.x = TRUE)
test_data$channel
str(test_data$channel)
test_data
test_data$channel
test_data[,"channel"]
setDT(news_source2)
head(news_source2)
merge(test_data, news_source2, by.x = channel, by.y = channel, all.x = TRUE)
merge(test_data, news_source2, by.x = "channel", by.y = "channel", all.x = TRUE)
new_test_data = merge(test_data, news_source2, by.x = "channel", by.y = "channel", all.x = TRUE)
write.csv(new_test_data, "~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv")
df = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"))
df = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"))
import(datatable)
library(datatable)
library(data.table)
df = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"))
df = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"))
df = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"))
df = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"))
head(df)
drop_na(df)
library(dplyr)
df %>% drop_na()
?drop_na
library(tidyverse)
df %>% drop_na()
head(df)
df %<>% drop_na()
df %>% drop_na()
df %<% df %>% drop_na()
df %<% drop_na()
df %>% drop_na()
df
df %>% drop_na()
df <- df %>% drop_na()
write.csv(df, "~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv")
#load cleaned channel dataset
df_updated = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"), drop=c('Column1'))
#load cleaned channel dataset
df_updated = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA")))
#load cleaned channel dataset
df_updated = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"))
#load media bias dataset
media_bias = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/media_bias_data.csv", drop='Website')
#merge cleaned channel dataset with media bias
df_merged = merge(df_updated,
media_bias,
by.x='media_bias',
by.y='News Source')
#merge cleaned channel dataset with media bias
df_merged = merge(df_updated,
media_bias,
by.x='media_bias',
by.y='News Source',
all.x=T)
#load cleaned channel dataset
df_updated = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"), drop=c('Column1'))
#merge cleaned channel dataset with media bias
df_merged = merge(df_updated,
media_bias,
by.x='media_bias',
by.y='News Source')
#load cleaned channel dataset
df_updated = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"), drop=c('Column1'))
#merge cleaned channel dataset with media bias
df_merged = merge(df_updated,
media_bias,
by.x='media_bias',
by.y='News Source')
#load cleaned channel dataset
df_updated = fread("~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/channels/20200507-033205_climate_change_channels_clean.csv", na.strings=c("","NA"), drop=c('Column1'))
#merge cleaned channel dataset with media bias
df_merged = merge(df_updated,
media_bias,
by.x='media_bias',
by.y='News Source')
#remove N column
df_merged[, 'N':=NULL]
#complete dataset
df_merged2 = merge(df_relevant,
df_merged,
by='channel')
# % of videos still present in raw dataset.
nrow(df_merged2) / nrow(df)
#table with count and percentage
tblFun <- function(x){
tbl <- table(x)
res <- cbind(tbl,round(prop.table(tbl)*100,2))
colnames(res) <- c('Count','Percentage')
res
}
#
group_by_bias = do.call(rbind,lapply(df_merged2[, 'Bias'],tblFun))
group_by_bias
write.csv(group_by_bias, "~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/nlp/20200507-033205_climate_change_nlp.csv", drop='Website')
write.csv(group_by_bias, "~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/nlp/20200507-033205_climate_change_nlp.csv")
#convert Bias into binary
#right = 1
#left = 0
mapping <- c("Left" = 0, "Left-Center" = 0,
"Least Biased" = 1, "Right" = 1, "Right-Center" = 1)
df_merged2$Bias_num <- mapping[df_merged2$Bias]
#keep columns title, description and Bias_num for NLP dataset
df_nlp = df_merged2[, c('Bias_num' ,'title', 'description', 'channel','id')]
write.csv(group_by_bias, "~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/nlp/20200507-033205_climate_change_bias.csv")
#export NLP dataset
write.csv(df_nlp, "~/Documents/GitHub/esade_fake_news/1_Climate_Change/youtube_query/data/nlp/20200507-033205_climate_change_nlp.csv")
# 32% Bias_num is 1, 68% is 0
sum(df_nlp$Bias_num) / nrow(df_nlp)
sum(df_nlp$Bias_num)
